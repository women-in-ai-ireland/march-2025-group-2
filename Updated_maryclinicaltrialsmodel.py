# -*- coding: utf-8 -*-
"""MaryClinicalTrialsModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZGAMH60zmbap7sjpu0KqzxxpLwbwFc3P
"""

#clinical_trial_model.py
import pandas as pd
import sqlite3
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

print("Loading dataset into SQLite database...")

#Load CSV

#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.
#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.
#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.
#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.

!pip install pandas scikit-learn joblib

from google.colab import files
uploaded = files.upload()  # Upload the CSV file you just provided

import pandas as pd

df = pd.read_csv("clinical_trial_dataset_1000.csv")
print("‚úÖ Dataset loaded")
df.head()

# Clean and inspect Dropout_Flag values
df["Dropout_Flag"] = df["Dropout_Flag"].str.strip().str.lower()

# Keep only rows with valid Yes/No labels
df = df[df["Dropout_Flag"].isin(["yes", "no"])]

# Convert Dropout_Flag to binary
df["Dropout_Flag"] = df["Dropout_Flag"].map({"yes": 1, "no": 0})

# Convert categorical features using dummy variables
categorical_cols = ["Gender", "Ethnicity", "Health_Condition", "Comorbidities", "Trial_Phase"]
df = pd.get_dummies(df, columns=categorical_cols)

# Drop unused columns
X = df.drop(columns=["Participant_ID", "Dropout_Reason", "Dropout_Flag"])
y = df["Dropout_Flag"]

print("‚úÖ Data preprocessing done")

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("‚úÖ Model trained")

from sklearn.metrics import classification_report

y_pred = model.predict(X_test)
print("\nüìä Classification Report:\n")
print(classification_report(y_test, y_pred))

import joblib
joblib.dump(model, "dropout_model.pkl")
print("‚úÖ Model saved as 'dropout_model.pkl'")

# Create a new participant (ensure it matches your dummy column names)
new_data = pd.DataFrame([{
    "Age": 55,
    "Side_Effects_Severity": 2,
    "Satisfaction_Score": 4,
    "Distance_to_Site_km": 10,
    "Visit_Frequency_per_Month": 3,
    "Gender_Female": 0,
    "Gender_Male": 1,
    "Ethnicity_Black": 0,
    "Ethnicity_White": 1,
    "Ethnicity_Asian": 0,
    "Health_Condition_Diabetes": 1,
    "Health_Condition_Hypertension": 0,
    "Comorbidities_None": 1,
    "Comorbidities_Heart Disease": 0,
    "Trial_Phase_Phase 1": 0,
    "Trial_Phase_Phase 2": 1,
    "Trial_Phase_Phase 3": 0
}])

# Align new_data with training columns
missing_cols = set(X.columns) - set(new_data.columns)
for col in missing_cols:
    new_data[col] = 0
new_data = new_data[X.columns]

# Predict
prediction = model.predict(new_data)[0]
probability = model.predict_proba(new_data)[0][1]

print(f"\nüß™ Predicted Dropout: {'Yes' if prediction == 1 else 'No'}")
print(f"üìà Probability of Dropout: {round(probability * 100, 2)}%")

#Creating a mini dasboard for summary metrics (accuracy, precision, recall, F1-score).
#Creating a Pie chart of actual dropout distribution
#Creating a Bar chart of feature importance

!pip install matplotlib seaborn

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("üìä MODEL METRICS")
print(f"‚úÖ Accuracy:  {accuracy:.2f}")
print(f"‚úÖ Precision: {precision:.2f}")
print(f"‚úÖ Recall:    {recall:.2f}")
print(f"‚úÖ F1 Score:  {f1:.2f}")

import matplotlib.pyplot as plt

labels = ["No Dropout", "Dropout"]
sizes = df["Dropout_Flag"].value_counts().sort_index()
colors = ["#66b3ff", "#ff9999"]

plt.figure(figsize=(5, 5))
plt.pie(sizes, labels=labels, colors=colors, autopct="%1.1f%%", startangle=140)
plt.title("üí° Actual Dropout Distribution")
plt.axis("equal")
plt.show()

import pandas as pd

importances = model.feature_importances_
features = X.columns
feat_importance = pd.Series(importances, index=features).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
feat_importance.head(10).plot(kind="barh", color="#72bcd4")
plt.title("üîç Top 10 Most Important Features")
plt.xlabel("Feature Importance")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("üìâ Confusion Matrix")
plt.tight_layout()
plt.show()

plt.savefig("chart_name.png", dpi=300)
files.download("chart_name.png")