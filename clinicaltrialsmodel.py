# -*- coding: utf-8 -*-
"""ClinicalTrialsModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZGAMH60zmbap7sjpu0KqzxxpLwbwFc3P
"""

#clinical_trial_model.py
import pandas as pd
import sqlite3
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

print("Loading dataset into SQLite database...")

#Load CSV

#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.
#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.
#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.
#Starting all over. Using an updated dataset with dummy variable this time - instead of labelencoder.

!pip install pandas scikit-learn joblib

from google.colab import files
uploaded = files.upload()  # Upload the CSV file you just provided

import pandas as pd

df = pd.read_csv("clinical_trial_dataset_1000.csv")
print("‚úÖ Dataset loaded")
df.head()

# Clean and inspect Dropout_Flag values
df["Dropout_Flag"] = df["Dropout_Flag"].str.strip().str.lower()

# Keep only rows with valid Yes/No labels
df = df[df["Dropout_Flag"].isin(["yes", "no"])]

# Convert Dropout_Flag to binary
df["Dropout_Flag"] = df["Dropout_Flag"].map({"yes": 1, "no": 0})

# Convert categorical features using dummy variables
categorical_cols = ["Gender", "Ethnicity", "Health_Condition", "Comorbidities", "Trial_Phase"]
df = pd.get_dummies(df, columns=categorical_cols)

# Drop unused columns
X = df.drop(columns=["Participant_ID", "Dropout_Reason", "Dropout_Flag"])
y = df["Dropout_Flag"]

print("‚úÖ Data preprocessing done")

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("‚úÖ Model trained")

from sklearn.metrics import classification_report

y_pred = model.predict(X_test)
print("\nüìä Classification Report:\n")
print(classification_report(y_test, y_pred))

import joblib
joblib.dump(model, "dropout_model.pkl")
print("‚úÖ Model saved as 'dropout_model.pkl'")

# Create a new participant (ensure it matches your dummy column names)
new_data = pd.DataFrame([{
    "Age": 55,
    "Side_Effects_Severity": 2,
    "Satisfaction_Score": 4,
    "Distance_to_Site_km": 10,
    "Visit_Frequency_per_Month": 3,
    "Gender_Female": 0,
    "Gender_Male": 1,
    "Ethnicity_Black": 0,
    "Ethnicity_White": 1,
    "Ethnicity_Asian": 0,
    "Health_Condition_Diabetes": 1,
    "Health_Condition_Hypertension": 0,
    "Comorbidities_None": 1,
    "Comorbidities_Heart Disease": 0,
    "Trial_Phase_Phase 1": 0,
    "Trial_Phase_Phase 2": 1,
    "Trial_Phase_Phase 3": 0
}])

# Align new_data with training columns
missing_cols = set(X.columns) - set(new_data.columns)
for col in missing_cols:
    new_data[col] = 0
new_data = new_data[X.columns]

# Predict
prediction = model.predict(new_data)[0]
probability = model.predict_proba(new_data)[0][1]

print(f"\nüß™ Predicted Dropout: {'Yes' if prediction == 1 else 'No'}")
print(f"üìà Probability of Dropout: {round(probability * 100, 2)}%")

#Creating a mini dasboard for summary metrics (accuracy, precision, recall, F1-score).
#Creating a Pie chart of actual dropout distribution
#Creating a Bar chart of feature importance

!pip install matplotlib seaborn

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("üìä MODEL METRICS")
print(f"‚úÖ Accuracy:  {accuracy:.2f}")
print(f"‚úÖ Precision: {precision:.2f}")
print(f"‚úÖ Recall:    {recall:.2f}")
print(f"‚úÖ F1 Score:  {f1:.2f}")

import matplotlib.pyplot as plt

labels = ["No Dropout", "Dropout"]
sizes = df["Dropout_Flag"].value_counts().sort_index()
colors = ["#66b3ff", "#ff9999"]

plt.figure(figsize=(5, 5))
plt.pie(sizes, labels=labels, colors=colors, autopct="%1.1f%%", startangle=140)
plt.title("üí° Actual Dropout Distribution")
plt.axis("equal")
plt.show()

import pandas as pd

importances = model.feature_importances_
features = X.columns
feat_importance = pd.Series(importances, index=features).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
feat_importance.head(10).plot(kind="barh", color="#72bcd4")
plt.title("üîç Top 10 Most Important Features")
plt.xlabel("Feature Importance")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("üìâ Confusion Matrix")
plt.tight_layout()
plt.show()

plt.savefig("chart_name.png", dpi=300)
files.download("chart_name.png")



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (classification_report, confusion_matrix,
                             roc_auc_score, roc_curve, accuracy_score,
                             precision_score, recall_score, f1_score)
from imblearn.over_sampling import SMOTE

print("\n[1/7] Loading data...")
try:
    df = pd.read_csv("clinical_trial_dataset_1000.csv")
except FileNotFoundError:
    print("ERROR: File 'clinical_trial_dataset_1000.csv' not found.")
    exit(1)
print(f"Initial data shape: {df.shape}")

# Clean Dropout_Flag and drop NA
df = df.dropna(subset=["Dropout_Flag"])
df["Dropout_Flag"] = df["Dropout_Flag"].astype(str).str.strip().str.lower()
df = df[df["Dropout_Flag"].isin(["yes", "no"])]
df["Dropout_Flag"] = df["Dropout_Flag"].map({"yes": 1, "no": 0})

# Drop obvious leakage/id columns if present
drop_cols = [col for col in ["Participant_ID", "Dropout_Reason"] if col in df.columns]
df = df.drop(columns=drop_cols, errors='ignore')

# Categorical columns to one-hot encode
cat_cols = [col for col in ["Gender", "Ethnicity", "Health_Condition", "Comorbidities", "Trial_Phase"] if col in df.columns]
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Demo feature engineering (add more as needed)
if "Satisfaction_Score" in df.columns and "Adherence_Score" in df.columns:
    df["Interaction_Score"] = df["Satisfaction_Score"] * df["Adherence_Score"]

X = df.drop(columns=["Dropout_Flag"])
y = df["Dropout_Flag"]

print("\n[2/7] Splitting data (80/20, stratified)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

print("\n[3/7] Applying SMOTE to handle class imbalance...")
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

print("\n[4/7] Model training: Random Forest and Logistic Regression (baseline)")
lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
y_proba_lr = lr.predict_proba(X_test)[:,1]

rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
y_proba_rf = rf.predict_proba(X_test)[:,1]

def show_results(y_true, y_pred, y_proba, model_name):
    print(f"\n---- {model_name} ----")
    print(classification_report(y_true, y_pred, digits=3))
    print(f"Accuracy:  {accuracy_score(y_true, y_pred):.2f}")
    print(f"Precision: {precision_score(y_true, y_pred):.2f}")
    print(f"Recall:    {recall_score(y_true, y_pred):.2f}")
    print(f"F1-score:  {f1_score(y_true, y_pred):.2f}")
    print(f"ROC AUC:   {roc_auc_score(y_true, y_proba):.2f}")
    # Plot confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["No Dropout", "Dropout"], yticklabels=["No Dropout", "Dropout"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix ({model_name})")
    plt.tight_layout()
    plt.show()
    # Plot ROC curve
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    plt.plot(fpr, tpr, label=f"{model_name} (AUC={roc_auc_score(y_true, y_proba):.2f})")
    plt.plot([0,1], [0,1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve: {model_name}")
    plt.legend()
    plt.show()

print("\n[5/7] Evaluation:")
show_results(y_test, y_pred_lr, y_proba_lr, "Logistic Regression")
show_results(y_test, y_pred_rf, y_proba_rf, "Random Forest")

# Feature importance (Random Forest)
importances = rf.feature_importances_
features = X.columns
fi = pd.Series(importances, index=features).sort_values(ascending=False)
plt.figure(figsize=(10, 5))
fi.head(10).plot(kind="barh", color="#2494bf")
plt.title("Top 10 Random Forest Feature Importances")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

print("\n[6/7] Saving model and columns for future use...")
joblib.dump(rf, "dropout_rf_model.pkl")
joblib.dump(list(X.columns), "dropout_rf_features.pkl")
print("Model and features saved as dropout_rf_model.pkl and dropout_rf_features.pkl.")

print("\nScript complete. Your model is ready to use!")

#trying again
#trying again

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (classification_report, confusion_matrix,
                             roc_auc_score, roc_curve, accuracy_score,
                             precision_score, recall_score, f1_score)
from imblearn.over_sampling import SMOTE

from google.colab import files
uploaded = files.upload()  # Upload the CSV file you just provided

import pandas as pd

df = pd.read_csv("clinical_trial_dataset_1000.csv")
print("‚úÖ Dataset loaded")
df.head()

# Clean Dropout_Flag and drop NA
df = df.dropna(subset=["Dropout_Flag"])
df["Dropout_Flag"] = df["Dropout_Flag"].astype(str).str.strip().str.lower()
df = df[df["Dropout_Flag"].isin(["yes", "no"])]
df["Dropout_Flag"] = df["Dropout_Flag"].map({"yes": 1, "no": 0})

# Drop obvious leakage/id columns if present
drop_cols = [col for col in ["Participant_ID", "Dropout_Reason"] if col in df.columns]
df = df.drop(columns=drop_cols, errors='ignore')

# Categorical columns to one-hot encode
cat_cols = [col for col in ["Gender", "Ethnicity", "Health_Condition", "Comorbidities", "Trial_Phase"] if col in df.columns]
df = pd.get_dummies(df, columns=cat_cols, drop_first=True)

# Demo feature engineering (add more as needed)
if "Satisfaction_Score" in df.columns and "Adherence_Score" in df.columns:
    df["Interaction_Score"] = df["Satisfaction_Score"] * df["Adherence_Score"]

X = df.drop(columns=["Dropout_Flag"])
y = df["Dropout_Flag"]

print("\n[2/7] Splitting data (80/20, stratified)...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

print("\n[3/7] Applying SMOTE to handle class imbalance...")
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

print("\n[4/7] Model training: Random Forest and Logistic Regression (baseline)")
lr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
y_proba_lr = lr.predict_proba(X_test)[:,1]

rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
y_proba_rf = rf.predict_proba(X_test)[:,1]

def show_results(y_true, y_pred, y_proba, model_name):
    print(f"\n---- {model_name} ----")
    print(classification_report(y_true, y_pred, digits=3))
    print(f"Accuracy:  {accuracy_score(y_true, y_pred):.2f}")
    print(f"Precision: {precision_score(y_true, y_pred):.2f}")
    print(f"Recall:    {recall_score(y_true, y_pred):.2f}")
    print(f"F1-score:  {f1_score(y_true, y_pred):.2f}")
    print(f"ROC AUC:   {roc_auc_score(y_true, y_proba):.2f}")
    # Plot confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["No Dropout", "Dropout"], yticklabels=["No Dropout", "Dropout"])
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title(f"Confusion Matrix ({model_name})")
    plt.tight_layout()
    plt.show()
    # Plot ROC curve
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    plt.plot(fpr, tpr, label=f"{model_name} (AUC={roc_auc_score(y_true, y_proba):.2f})")
    plt.plot([0,1], [0,1], 'k--')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve: {model_name}")
    plt.legend()
    plt.show()

print("\n[5/7] Evaluation:")
show_results(y_test, y_pred_lr, y_proba_lr, "Logistic Regression")
show_results(y_test, y_pred_rf, y_proba_rf, "Random Forest")

# Feature importance (Random Forest)
importances = rf.feature_importances_
features = X.columns
fi = pd.Series(importances, index=features).sort_values(ascending=False)
plt.figure(figsize=(10, 5))
fi.head(10).plot(kind="barh", color="#2494bf")
plt.title("Top 10 Random Forest Feature Importances")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

print("\n[6/7] Saving model and columns for future use...")
joblib.dump(rf, "dropout_rf_model.pkl")
joblib.dump(list(X.columns), "dropout_rf_features.pkl")
print("Model and features saved as dropout_rf_model.pkl and dropout_rf_features.pkl.")

print("\nScript complete. Your model is ready to use!")